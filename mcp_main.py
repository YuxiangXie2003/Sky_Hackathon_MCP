"""
streamlit_llm_travel_app.py
"""
import streamlit as st
from audiorecorder import audiorecorder
from io import BytesIO
import os, asyncio, logging
from pydub import AudioSegment
import streamlit.components.v1 as components
from dotenv import load_dotenv

# ä½ çš„éŸ³é¢‘è½¬æ–‡å­—å‡½æ•°
from mcp_module import audio_to_text

# =========  LLM Bridge  ========= #
from mcp import StdioServerParameters
from mcp_llm_bridge.config import BridgeConfig, LLMConfig
from mcp_llm_bridge.bridge import BridgeManager

# ---------- Bridge åˆå§‹åŒ–ï¼ˆä¸€æ¬¡å°±å¤Ÿï¼Œæ”¾åˆ° session_state ä¿æŒé•¿è¿ï¼‰ ---------- #
def init_bridge():
    load_dotenv()                                     # è¯»å– .env ç¯å¢ƒå˜é‡
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    db_path = os.path.join(project_root, "test.db")   # å¦‚æœç”¨å¾—åˆ°

    cfg = BridgeConfig(
        mcp_server_params=StdioServerParameters(
            command="python",
            args=["tool_hub.py"],
            env=None
        ),
        llm_config=LLMConfig(
            api_key = os.getenv("NVIDIA_API_KEY"),
            model="nvidia/llama-3.1-nemotron-ultra-253b-v1",
            base_url="https://integrate.api.nvidia.com/v1"
        ),
        # system_prompt=(
        #     "ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ï¼Œå¯ä»¥ä¸ºç”¨æˆ·æä¾›åŸå¸‚å‡ºè¡Œæ”»ç•¥ï¼ŒåŒ…æ‹¬ï¼šå¤©æ°”é¢„æŠ¥ã€"
        #     "æ™¯ç‚¹æ¨èå’Œåœ°å›¾å®šä½ã€‚è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„åŸå¸‚åï¼Œä¾æ¬¡è°ƒç”¨ï¼š"
        #     "1. weather_search(city)  2. generate_static_map(city)ã€‚"
        #     "è¾“å‡ºè´´è¿‘å°çº¢ä¹¦é£æ ¼ï¼ŒæŒ‰ Day1/Day2 çš„æ ¼å¼è·¯çº¿è§„åˆ’ï¼Œå¹¶é™„åœ°å›¾æç¤ºã€‚"
        # )
        system_prompt=(
            "ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ï¼Œå¯ä»¥ä¸ºç”¨æˆ·æä¾›åŸå¸‚å‡ºè¡Œæ”»ç•¥ï¼ŒåŒ…æ‹¬ï¼šå¤©æ°”é¢„æŠ¥ã€æ™¯ç‚¹æ¨èå’Œåœ°å›¾å®šä½ã€‚"
            "è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„åŸå¸‚åï¼Œä¾æ¬¡è°ƒç”¨ä»¥ä¸‹å·¥å…·ï¼š"
            "1. `weather_search(city)`ï¼šæŸ¥è¯¢è¯¥åŸå¸‚æœªæ¥å‡ å¤©å¤©æ°”ï¼Œå¹¶æå–æ¯æ—¥å¤©æ°”ã€æ°”æ¸©ã€é£åŠ›ä¿¡æ¯ï¼Œæ•´ç†æˆäº²åˆ‡è‡ªç„¶çš„è¯­æ°”ã€‚"
            "2. `generate_static_map(city)`ï¼šæŸ¥è¯¢è¯¥åŸå¸‚çš„è‘—åæ™¯ç‚¹ï¼Œå¹¶ç”Ÿæˆåœ°å›¾"
            "è¾“å‡ºè¦æ±‚ï¼š"
            "- ä½¿ç”¨ä¸­æ–‡ï¼Œé£æ ¼è´´è¿‘â€œå°çº¢ä¹¦â€æˆ–å¾®ä¿¡å…¬ä¼—å·æ—…æ¸¸åšä¸»æ–‡æ¡ˆï¼Œäº²åˆ‡æœ‰æ¸©åº¦ã€‚"
            "- æ¯å¤©çš„å¤©æ°”ç”¨ emoji è¡¨ç¤ºï¼ˆå¦‚ â˜€ï¸ã€ğŸŒ§ï¸ï¼‰ï¼Œæ¢è¡Œå±•ç¤ºï¼Œæ³¨æ„ä¸è¦é‡å¤è¯´â€œå¤©æ°”å¦‚ä¸‹â€ç­‰ã€‚"
            "- å°†å‡½æ•°è¿”å›çš„æ™¯ç‚¹åˆ†ç»„ï¼Œåˆç†è§„åˆ’ä¸ºæ¯ä¸€å¤©è·¯çº¿ï¼Œç»“åˆåŸå¸‚ç‰¹è‰²å®‰æ’é¡ºåºã€‚æ³¨æ„ä¸è¦æ·»åŠ å‡½æ•°è¿”å›çš„æ™¯ç‚¹ä¹‹å¤–çš„æ™¯ç‚¹"
            "- æ·»åŠ è´´å¿ƒå°è´´å£«ï¼Œå¦‚å»ºè®®äº¤é€šæ–¹å¼ã€é›¨å…·å‡†å¤‡ã€æ¸¸ç©èŠ‚å¥ã€‚"
            "- æœ€åé™„ä¸Šåœ°å›¾ç”Ÿæˆæç¤ºï¼Œä¾‹å¦‚ï¼šâ€œğŸ—ºï¸åœ°å›¾å·²ç”Ÿæˆï¼Œåœ¨ä¸‹æ–¹æŸ¥çœ‹æ‰€æœ‰æ™¯ç‚¹ä½ç½®â€ã€‚"
            "ä½ ä¸éœ€è¦è¯´æ˜å·¥å…·çš„ä½¿ç”¨è¿‡ç¨‹ï¼Œåªè¾“å‡ºæ•´ç†åçš„å†…å®¹å³å¯ï¼Œç›´æ¥å›å¤ç»™ç”¨æˆ·ã€‚"
        )
    )
    return BridgeManager(cfg)

if "bridge" not in st.session_state:
    st.session_state.bridge = init_bridge()

# åŒæ­¥åŒ…è£…ï¼šå‘ LLM å‘é€ user_inputï¼Œæ‹¿åˆ° response
def llm_chat_sync(user_input: str) -> str:
    async def _chat(prompt: str) -> str:
        async with st.session_state.bridge as bridge:
            return await bridge.process_message(prompt)
    return asyncio.run(_chat(user_input))

# =========  Streamlit UI  ========= #
st.set_page_config(page_title="æ—…å›¾é€šâ€”â€”ä½ çš„æ—…æ¸¸è§„åˆ’æ™ºèƒ½ä½“")
st.title("æ—…å›¾é€šâ€”â€”ä½ çš„æ—…æ¸¸è§„åˆ’æ™ºèƒ½ä½“")

# å¤§æ ‡é¢˜
st.markdown("## é€‰æ‹©è¾“å…¥æ–¹å¼")  # â€˜##â€™ = H2 çº§æ ‡é¢˜ï¼Œå¯æ ¹æ®éœ€è¦æ”¹æˆ ###ã€#### â€¦

# æŠŠ radio è‡ªå¸¦çš„ label éšè—
input_method = st.radio(
    label="placeholder",              # éšä¾¿å†™
    options=["è¯­éŸ³è¾“å…¥", "ä¸Šä¼ æ–‡ä»¶", "æ–‡æœ¬è¾“å…¥"],
    label_visibility="collapsed"      # å…³é”®å‚æ•°ï¼šéšè—æ ‡ç­¾
)

result_text, model_output = None, None

# ğŸ™ï¸ è¯­éŸ³è¾“å…¥
if input_method == "è¯­éŸ³è¾“å…¥":
    st.subheader("ğŸ™ï¸ å½•éŸ³è¾“å…¥")
    audio_file_path = "audio/input.wav"
    os.makedirs("audio", exist_ok=True)
    if os.path.exists(audio_file_path):
        os.remove(audio_file_path)

    audio = audiorecorder("ç‚¹å‡»å¼€å§‹å½•éŸ³", "ç‚¹å‡»åœæ­¢")
    if audio:
        # st.write(f"å½•éŸ³æ—¶é•¿: {audio.duration_seconds:.2f} ç§’")
        # st.write(f"æœ€å¤§éŸ³é‡: {audio.max_dBFS:.2f} dBFS")

        wav_io = BytesIO()
        audio.export(wav_io, format="wav"); wav_io.seek(0)
        st.audio(wav_io, format="audio/wav")

        audio.export(audio_file_path, format="wav")
        st.success("éŸ³é¢‘å·²ä¿å­˜")

        with st.spinner("ğŸ¤ æ­£åœ¨è¯†åˆ«..."):
            result_text = asyncio.run(audio_to_text(audio_file_path))

# ğŸ“ æ–‡ä»¶ä¸Šä¼ 
elif input_method == "ä¸Šä¼ æ–‡ä»¶":
    st.subheader("ğŸ“ ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
    uploaded = st.file_uploader("ä¸Šä¼  WAV æ–‡ä»¶", type=["wav"])
    if uploaded:
        audio_file_path = "audio/uploaded.wav"
        with open(audio_file_path, "wb") as f:
            f.write(uploaded.read())
        st.audio(audio_file_path, format="audio/wav")
        if st.button("å¤„ç†æ–‡ä»¶"):
            with st.spinner("ğŸ¤ æ­£åœ¨è¯†åˆ«..."):
                result_text = asyncio.run(audio_to_text(audio_file_path))
    else:
        st.button("è¯·å…ˆä¸Šä¼ æ–‡ä»¶", disabled=True)

# âœï¸ æ–‡æœ¬è¾“å…¥
else:
    st.subheader("âœï¸ æ–‡æœ¬è¾“å…¥")
    text_input = st.text_area("è¯·è¾“å…¥å†…å®¹ï¼š", "ä¸Šæµ·")
    if st.button("å¤„ç†æ–‡æœ¬"):
        if text_input.strip():
            result_text = text_input.strip()
        else:
            st.warning("æ–‡æœ¬ä¸èƒ½ä¸ºç©º")

# ğŸ§  LLM å¤„ç†ä¸å±•ç¤º
if result_text:
    st.markdown("#### ğŸ§ ä½ è¾“å…¥çš„å†…å®¹æ˜¯ï¼š")
    st.info(result_text)
    st.markdown("---")
    st.subheader("â³ æ­£åœ¨ç”Ÿæˆæ—…è¡Œæ”»ç•¥ ...")
    with st.spinner("LLM æ€è€ƒä¸­..."):
        try:
            model_output = llm_chat_sync(result_text)
        except Exception as e:
            st.error(f"è°ƒç”¨ LLM å‡ºé”™ï¼š{e}")
            model_output = None

# âœ… å±•ç¤ºç»“æœ
if model_output:
    st.success("LLM å·²ç”ŸæˆğŸ‘‡")
    st.markdown(model_output)

    # å¦‚æœåœ°å›¾æ–‡ä»¶å­˜åœ¨å°±å±•ç¤º
    if os.path.exists("landmarks_map.png"):
        st.image("landmarks_map.png", caption="ğŸ—ºï¸ æ—…è¡Œåœ°å›¾", use_container_width=True)

    # è‡ªåŠ¨æœ—è¯»
    components.html(f"""
        <script>
            const msg = new SpeechSynthesisUtterance("{model_output}");
            window.speechSynthesis.speak(msg);
        </script>
    """, height=0)
